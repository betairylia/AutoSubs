# Default configuration for AutoSubs project
project_name: "AutoSubs"
version: "1.0.0"
description: "ML-based auto timing for subtitling"
seed: 42
debug: false

# Model configuration
model:
  # Audio backbone configuration
  backbone:
    type: "whisper"  # "conv1d", "transformer", or "whisper"
    
    # Conv1D parameters (if type == "conv1d")
    channels: [64, 128, 256, 512]
    kernel_sizes: [3, 3, 3, 3]
    strides: [1, 2, 2, 2]
    
    # Transformer parameters (if type == "transformer")
    d_model: 256
    n_heads: 8
    n_layers: 6
    d_ff: 1024
    dropout: 0.1
    
    # Whisper parameters (if type == "whisper")
    whisper_model_size: "base"  # "tiny", "base", "small", "medium", "large"
    
    # Common parameters
    input_dim: 80   # mel spectrogram dimension (Whisper pretrained)
    output_dim: 512  # feature dimension (matches Whisper base model)
  
  # Head configuration
  head:
    hidden_dims: [512]  # Adjusted for larger Whisper features
    dropout: 0.1
    activation: "relu"
    feature_dim: 16  # dimension of feature vectors for pairing
  
  # Post-processing parameters
  nmp_window_size: 5
  confidence_threshold: 0.5
  feature_distance_threshold: 2.0
  max_subtitle_length: 10.0

# Data processing configuration
data:
  # File discovery
  audio_extensions: [".mp3", ".wav", ".ogg", ".m4a", ".aac"]
  subtitle_extensions: [".ass"]
  
  # Audio processing
  audio:
    sample_rate: 16000   # Whisper requirement
    n_mels: 80          # Whisper pretrained models use 80/128 mels
    n_fft: 400           # Whisper requirement
    hop_length: 160      # Whisper requirement (10ms frames)
    win_length: 400      # Should match n_fft for Whisper
    normalize: true
    use_whisper_preprocessing: true   # Use Whisper's preprocessing for optimal results
  
  # Chunking configuration
  chunking:
    chunk_duration: 30.0  # seconds (matches Whisper)
    overlap_ratio: 0.1  # 10% overlap
    padding_duration: 2.0  # seconds
    timing_fps: 100  # frames per second for timing (Whisper encoder outputs 100fps)
  
  # Label processing
  labels:
    gaussian_sigma: 0.05  # seconds
    merge_same_timestamp: true
    timestamp_tolerance: 0.1  # seconds
  
  # Dataset parameters
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  random_seed: 42
  dataset_format: "pytorch"
  cache_dir: "./cache"

# Training configuration
training:
  # Basic training parameters
  epochs: 100
  batch_size: 16
  accumulate_grad_batches: 1
  grad_clip_norm: 1.0
  
  # Device and performance
  device: "auto"  # auto-detect
  num_workers: 0
  pin_memory: true
  
  # Validation and checkpointing
  val_check_interval: 1000
  save_top_k: 3
  save_every_n_epochs: 10
  
  # Early stopping
  early_stopping_patience: 70
  early_stopping_min_delta: 0.0001
  
  # Logging
  log_every_n_steps: 50
  log_dir: "./logs"
  experiment_name: "autosubs"
  
  # Optimizer configuration
  optimizer:
    type: "adam"
    lr: 0.001
    weight_decay: 0.0001
    betas: [0.9, 0.999]
    eps: 1e-8
  
  # Scheduler configuration
  scheduler:
    type: "cosine"
    T_max: 100
    eta_min: 1e-6
  
  # Loss configuration
  loss:
    focal_alpha: -1.0 # Negative for adaptive alpha
    focal_gamma: 2.0
    focal_alpha_ema_momentum: 0.9  # EMA momentum for adaptive alpha smoothing
    feature_margin: 1.0
    temperature: 0.1
    heatmap_weight: 1.0
    feature_weight: 0.1
  
  # Mixed precision
  use_amp: false